{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConvLSTM\n",
    "\n",
    "## Pre-setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries.\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import datetime as datetime\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "from moviepy.editor import *\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from batch_data_generator import DataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import tensorflow and check for GPU support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print num of GPUs if available to use\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set a seed to reproduce the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_constant = 123\n",
    "np.random.seed(seed_constant)\n",
    "random.seed(seed_constant)\n",
    "tf.random.set_seed(seed_constant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set data directories and other constants for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data paths are defined here\n",
    "DATA_DIR = 'data'\n",
    "VIDEO_PATH = os.path.join(DATA_DIR, 'videos')\n",
    "ANNOTATION_PATH = os.path.join(DATA_DIR, 'annotations')\n",
    "TRAINING_PATH = os.path.join(VIDEO_PATH, 'training')\n",
    "TESTING_PATH = os.path.join(VIDEO_PATH, 'testing')\n",
    "VALIDATION_PATH = os.path.join(VIDEO_PATH, 'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the number of frames of a video that will be fed to the model as one sequence.\n",
    "SEQUENCE_LENGTH = 30\n",
    "\n",
    "# Set a minimum duration in seconds to extract sequence in multiples of\n",
    "MIN_DURATION = 150\n",
    "\n",
    "(DIMENSION_X, DIMENSION_Y, DIMENSION_C) = (224, 224, 3)\n",
    "\n",
    "# Get the names of all classes/categories in our dataset.\n",
    "CLASSES_LIST = os.listdir(TRAINING_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a easily readable class name mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_mapping = {\n",
    "'_cut___chop___slice_a_vegetable,_fruit,_or_meat_' : 'cut vegetables, herbs or meat',\n",
    "'browse_through_clothing_items_on_rack___shelf___hanger' : 'browse through clothing items',\n",
    "'clean___wipe_other_surface_or_object' : 'clean surface',\n",
    "'dig_or_till_the_soil_with_a_hoe_or_other_tool' : 'till soil with a hoe',\n",
    "'read_a_book___magazine___shopping_list_etc' : 'read a book',\n",
    "'throw_away_trash___put_trash_in_trash_can' : 'throw away trash',\n",
    "'wash_dishes___utensils___bakeware_etc' : 'wash utensils'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read npy files in data generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the file paths and corresponsing labels for the data generator (**Run everytime kernel is (re)started**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nparray_and_labels_in_partition(partition_path):\n",
    "\tnparrayfile_paths = []\n",
    "\tlabels = {}\n",
    "\tfor class_name in os.listdir(partition_path):\n",
    "\t\tif class_name not in CLASSES_LIST:\n",
    "\t\t\tprint(f'{class_name} not found in class list!')\n",
    "\t\t\tcontinue\n",
    "\t\tfor video_file_name in os.listdir(os.path.join(partition_path, class_name)):\n",
    "\t\t\tif not video_file_name.endswith('.npy'): continue\n",
    "\t\t\tnparrayfile_path = os.path.join(partition_path, class_name, video_file_name)\n",
    "\t\t\tnparrayfile_paths.append(nparrayfile_path)\n",
    "\t\t\tlabels[nparrayfile_path] = CLASSES_LIST.index(class_name)\n",
    "\treturn nparrayfile_paths, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into train, validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nparray_partition = {}\n",
    "nparray_labels = {}\n",
    "nparray_partition['train'], nparray_labels['train'] = get_nparray_and_labels_in_partition(TRAINING_PATH)\n",
    "nparray_partition['test'], nparray_labels['test'] = get_nparray_and_labels_in_partition(TESTING_PATH)\n",
    "nparray_partition['validation'], nparray_labels['validation'] = get_nparray_and_labels_in_partition(VALIDATION_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define parameters for data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_generator_params = {\n",
    "\t'batch_size' : 25,\n",
    "\t'sequence_length' : SEQUENCE_LENGTH,\n",
    "\t'n_classes' : len(CLASSES_LIST),\n",
    "\t'min_duration' : MIN_DURATION,\n",
    "\t'shuffle' : True\n",
    "}\n",
    "\n",
    "validation_data_generator_params = {\n",
    "\t'batch_size' : 25,\n",
    "\t'sequence_length' : SEQUENCE_LENGTH,\n",
    "\t'n_classes' : len(CLASSES_LIST),\n",
    "\t'min_duration' : MIN_DURATION,\n",
    "\t'shuffle' : True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_generator = DataGenerator(nparray_partition['train'], nparray_labels['train'], **train_data_generator_params)\n",
    "validation_generator = DataGenerator(nparray_partition['validation'], nparray_labels['validation'], **validation_data_generator_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model - ConvLSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import ConvLSTM2D, MaxPooling3D, TimeDistributed, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to create keras sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_convlstm_model():\n",
    "    '''\n",
    "    This function will construct the required convlstm model.\n",
    "    Returns:\n",
    "        model: It is the required constructed convlstm model.\n",
    "    '''\n",
    "\n",
    "    # We will use a Sequential model for model construction\n",
    "    model = Sequential()\n",
    "\n",
    "    # Define the Model Architecture.\n",
    "    ########################################################################################################################\n",
    "    \n",
    "    model.add(ConvLSTM2D(filters = 4, kernel_size = (3, 3), activation = 'tanh',data_format = \"channels_last\",\n",
    "                         recurrent_dropout=0.2, return_sequences=True, input_shape = (SEQUENCE_LENGTH,\n",
    "                                                                                      DIMENSION_X, DIMENSION_Y, DIMENSION_C)))\n",
    "    \n",
    "    model.add(MaxPooling3D(pool_size=(1, 2, 2), padding='same', data_format='channels_last'))\n",
    "    model.add(TimeDistributed(Dropout(0.2)))\n",
    "    \n",
    "    model.add(ConvLSTM2D(filters = 8, kernel_size = (3, 3), activation = 'tanh', data_format = \"channels_last\",\n",
    "                         recurrent_dropout=0.2, return_sequences=True))\n",
    "    \n",
    "    model.add(MaxPooling3D(pool_size=(1, 2, 2), padding='same', data_format='channels_last'))\n",
    "    model.add(TimeDistributed(Dropout(0.2)))\n",
    "    \n",
    "    model.add(ConvLSTM2D(filters = 14, kernel_size = (3, 3), activation = 'tanh', data_format = \"channels_last\",\n",
    "                         recurrent_dropout=0.2, return_sequences=True))\n",
    "    \n",
    "    model.add(MaxPooling3D(pool_size=(1, 2, 2), padding='same', data_format='channels_last'))\n",
    "    model.add(TimeDistributed(Dropout(0.2)))\n",
    "    \n",
    "    model.add(ConvLSTM2D(filters = 16, kernel_size = (3, 3), activation = 'tanh', data_format = \"channels_last\",\n",
    "                         recurrent_dropout=0.2, return_sequences=True))\n",
    "    \n",
    "    model.add(MaxPooling3D(pool_size=(1, 2, 2), padding='same', data_format='channels_last'))\n",
    "    #model.add(TimeDistributed(Dropout(0.2)))\n",
    "    \n",
    "    model.add(Flatten()) \n",
    "    \n",
    "    model.add(Dense(len(CLASSES_LIST), activation = \"softmax\"))\n",
    "    \n",
    "    ########################################################################################################################\n",
    "     \n",
    "    # Display the models summary.\n",
    "    model.summary()\n",
    "    \n",
    "    # Return the constructed convlstm model.\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv_lstm2d (ConvLSTM2D)    (None, 30, 222, 222, 4)   1024      \n",
      "                                                                 \n",
      " max_pooling3d (MaxPooling3D  (None, 30, 111, 111, 4)  0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, 30, 111, 111, 4)  0         \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      " conv_lstm2d_1 (ConvLSTM2D)  (None, 30, 109, 109, 8)   3488      \n",
      "                                                                 \n",
      " max_pooling3d_1 (MaxPooling  (None, 30, 55, 55, 8)    0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDis  (None, 30, 55, 55, 8)    0         \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " conv_lstm2d_2 (ConvLSTM2D)  (None, 30, 53, 53, 14)    11144     \n",
      "                                                                 \n",
      " max_pooling3d_2 (MaxPooling  (None, 30, 27, 27, 14)   0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " time_distributed_2 (TimeDis  (None, 30, 27, 27, 14)   0         \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " conv_lstm2d_3 (ConvLSTM2D)  (None, 30, 25, 25, 16)    17344     \n",
      "                                                                 \n",
      " max_pooling3d_3 (MaxPooling  (None, 30, 13, 13, 16)   0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 81120)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 7)                 567847    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 600,847\n",
      "Trainable params: 600,847\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model Created Successfully!\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "# Construct the required convlstm model.\n",
    "convlstm_model = create_convlstm_model()\n",
    "\n",
    "# Display the success message. \n",
    "print(\"Model Created Successfully!\")\n",
    "plot_model(convlstm_model, to_file = 'convlstm_model_structure_plot.png', show_shapes = True, show_layer_names = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 7.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create an Instance of Early Stopping Callback\n",
    "early_stopping_callback = EarlyStopping(monitor = 'val_loss', patience = 10, mode = 'min', restore_best_weights = True)\n",
    "\n",
    "# Compile the model and specify loss function, optimizer and metrics values to the model\n",
    "convlstm_model.compile(loss = 'categorical_crossentropy', optimizer = 'Adam', metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Start training the model.\n",
    "convlstm_model_training_history = convlstm_model.fit(x = training_generator, \n",
    "    validation_data = validation_generator,\n",
    "    use_multiprocessing=True,\n",
    "    workers=6, \n",
    "    epochs = 20,\n",
    "    callbacks = [early_stopping_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the trained model.\n",
    "model_evaluation_history = convlstm_model.evaluate(x = validation_generator, use_multiprocessing=True, workers=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO-DO:\n",
    "\n",
    "- Explore different params to finetune model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('ACVPR')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7b16c9da95f04883170e058a5ab5debfb744b1406582038da61280139aa5eca4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
