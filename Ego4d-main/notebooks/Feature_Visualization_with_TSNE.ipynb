{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64f0eeb1",
   "metadata": {},
   "source": [
    "# Feature Visualization\n",
    "\n",
    "This is an example to show how to use visual features in Ego4D. This notebook uses the action features from the SlowFast model. The SlowFast model gives us features from both the slow pathway and the fast pathway.\n",
    "\n",
    "This notebook:\n",
    "1. Loads features\n",
    "    - This assumes your features have been downloaded and are locally available in some directory on your machine.\n",
    "    a) Aggregates the features into a fixed window size\n",
    "       - This can be set in the \"customize variables\" section\n",
    "2. Runs TSNE\n",
    "3. Visualizes them in plotly\n",
    "4. View videos\n",
    "\n",
    "Please note that SlowFast action features are every 16 frames (0.5333s).\n",
    "\n",
    "## Requirements\n",
    "- plotly\n",
    "- sklearn\n",
    "- pytorch\n",
    "- moviepy (optional)\n",
    "   - For visualization in juypter moviepy is used\n",
    "   \n",
    "## Notes\n",
    "- See: https://ego4d-data.org/docs/data/features/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1c0603",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "USING_SKLEARN = True\n",
    "from sklearn import preprocessing\n",
    "try:\n",
    "    # https://pypi.org/project/tsne-torch/\n",
    "    # https://github.com/CannyLab/tsne-cuda/blob/master/INSTALL.md\n",
    "    from tsnecuda import TSNE\n",
    "    USING_SKLEARN = False\n",
    "    print(\"Using CannyLab's tsnecuda\")\n",
    "except:\n",
    "    from sklearn.manifold import TSNE\n",
    "\n",
    "from moviepy.editor import VideoFileClip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0c3fe6",
   "metadata": {},
   "source": [
    "# Customize Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5771bbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "EGO4D_JSON_PATH = \"/private/home/miguelmartin/ego4d/ego4d.json\"\n",
    "FEATURE_DIR = \"/datasets01/ego4d_track2/v1/slowfast8x8_r101_k400\"\n",
    "VIDEOS_DIR = \"/datasets01/ego4d_track2/v1/full_scale/\"\n",
    "\n",
    "NUM_VIDEOS_LIMIT = -1  # use -1 for no limit\n",
    "\n",
    "# how many seconds to reduce each point to\n",
    "AGGREGATION_SEC = 600  # every 30s of video\n",
    "\n",
    "FEATURE_STRIDE = 16\n",
    "FEATURE_WINDOW_SIZE = 32\n",
    "FPS = 30\n",
    "\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a571b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sec_to_window_size(sec, stride_frames, window_size_frames, fps):\n",
    "    if sec == -1:\n",
    "        return -1\n",
    "    \n",
    "    num_frames = sec * fps - window_size_frames\n",
    "    return math.ceil(num_frames / stride_frames + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b8d16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "AGGR_WINDOW_SIZE_FRAMES = sec_to_window_size(AGGREGATION_SEC, FEATURE_STRIDE, FEATURE_WINDOW_SIZE, FPS)\n",
    "AGGR_WINDOW_SIZE_FRAMES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b436db75",
   "metadata": {},
   "source": [
    "# 1 - Load Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6e06c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_in_region(t, t1, t2):\n",
    "    return t >= t1 and t <= t2\n",
    "\n",
    "def is_in_any_region(t, start_ends):\n",
    "    for red in start_ends:\n",
    "        if is_in_region(t, red[\"start_sec\"], red[\"end_sec\"]):\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e94dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_idx_to_time(start, end, uid):\n",
    "    t_start_frames = start*FEATURE_STRIDE\n",
    "    t_end_frames = end*FEATURE_STRIDE+FEATURE_WINDOW_SIZE\n",
    "    t_s = t_start_frames / FPS\n",
    "    t_e = t_end_frames / FPS\n",
    "    \n",
    "    meta = meta_for_features[uid][\"video_metadata\"]\n",
    "    vid_dur = meta[\"video_duration_sec\"] + meta[\"video_start_sec\"] \n",
    "    if t_e > vid_dur:\n",
    "        return t_s, vid_dur\n",
    "    return t_s, t_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8f4cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_paths = [os.path.join(FEATURE_DIR, x) for x in os.listdir(FEATURE_DIR) if x.endswith(\".pt\")]\n",
    "random.shuffle(feature_paths)\n",
    "\n",
    "feature_uids = [path.split(\"/\")[-1][:-3] for path in feature_paths]  # remove \".pt\"\n",
    "features_to_load = {\n",
    "    uid: path\n",
    "    for uid, path in zip(feature_uids, feature_paths)\n",
    "}\n",
    "\n",
    "metadata = json.load(open(EGO4D_JSON_PATH))\n",
    "meta_per_uid = {v[\"video_uid\"]: v for v in metadata[\"videos\"]}\n",
    "meta_for_features = {k: v for k, v in meta_per_uid.items() if k in feature_uids}\n",
    "\n",
    "def get_agg_features(feature_path, uid, window_size):\n",
    "    f = torch.load(feature_path)\n",
    "#     print(f.shape)\n",
    "    return [\n",
    "        (f[i:i+window_size].mean(0), i, min(i + window_size - 1, len(f) - 1))\n",
    "        for i in range(0, f.shape[0], window_size)\n",
    "        # remove outlier features\n",
    "        if \n",
    "        (\n",
    "            f[i:i+window_size].shape[0] >= int(0.5*window_size)\n",
    "            or window_size >= f.shape[0]\n",
    "        )\n",
    "        and \n",
    "        not (\n",
    "            is_in_any_region(\n",
    "                frame_idx_to_time(i, i+window_size-1, uid)[0], meta_for_features[uid]['redacted_intervals']\n",
    "            )\n",
    "            or\n",
    "            is_in_any_region(\n",
    "                frame_idx_to_time(i, i+window_size-1, uid)[1], meta_for_features[uid]['redacted_intervals']\n",
    "            )\n",
    "        )\n",
    "    ]\n",
    "\n",
    "feature_uids = feature_uids[0:NUM_VIDEOS_LIMIT] if NUM_VIDEOS_LIMIT != -1 else feature_uids\n",
    "features = [\n",
    "    (uid, get_agg_features(features_to_load[uid], uid, AGGR_WINDOW_SIZE_FRAMES))\n",
    "    for uid in feature_uids\n",
    "]\n",
    "\n",
    "feature_with_identifiers = [(x, (uid, i, j)) for uid, xx in features for x, i, j in xx]\n",
    "agg_features = torch.stack([x for x, _ in feature_with_identifiers])\n",
    "video_indices = [idx for _, idx in feature_with_identifiers]\n",
    "len(agg_features), len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9a9982",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "video_uids = [uid for uid, _, _ in video_indices]\n",
    "start_end_times = [frame_idx_to_time(start, end, uid) for uid, start, end in video_indices]\n",
    "labels = [f\"{i}\" for i, _, _ in video_indices]\n",
    "\n",
    "start_end_times[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f06f17",
   "metadata": {},
   "source": [
    "# 2 - Run TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c763c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {}\n",
    "if not USING_SKLEARN:\n",
    "    # some decent parameters for the entire dataset\n",
    "    kwargs = {\n",
    "        \"n_iter\": 300000,\n",
    "        \"learning_rate\": 1.5,\n",
    "    }\n",
    "    assert len(features) < 10000, \"are you sure you want run SKLearn with this many features? (it's slow)\"\n",
    "kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c45d9a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "X = agg_features\n",
    "X_norm = preprocessing.MinMaxScaler(feature_range=(-1, 1)).fit_transform(X)\n",
    "X_tsne = TSNE(\n",
    "    n_components=2,\n",
    "    verbose=1,\n",
    "    perplexity=300.0, # for the entire dataset\n",
    "#     perplexity=500.0, # for the entire dataset\n",
    "    **kwargs,\n",
    ").fit_transform(X_norm)\n",
    "t2 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e35ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 - t1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7acabb",
   "metadata": {},
   "source": [
    "# 3 - Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f375e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xys = X_tsne.tolist()\n",
    "data_df = {\n",
    "    \"x\": [x for x, _ in xys],\n",
    "    \"y\": [y for _, y in xys],\n",
    "    \"labels\": labels,\n",
    "    \"feature_idx\": [idx for idx in range(len(xys))],\n",
    "    \"video_uid\": [uid for uid in video_uids],\n",
    "    \"start_s\": [t1 for t1, t2 in start_end_times],\n",
    "    \"end_s\": [t2 for t1, t2 in start_end_times],\n",
    "    \"scenarios\": [meta_for_features[uid][\"scenarios\"] for uid in video_uids],\n",
    "    \"is_redacted\": [\n",
    "        is_in_any_region(ts[0], meta_for_features[uid]['redacted_intervals'])\n",
    "        and is_in_any_region(ts[1], meta_for_features[uid]['redacted_intervals'])\n",
    "        for uid, ts in zip(video_uids, start_end_times)\n",
    "    ],\n",
    "    \"has_redacted\": [\n",
    "        is_in_any_region(ts[0], meta_for_features[uid]['redacted_intervals'])\n",
    "        or is_in_any_region(ts[1], meta_for_features[uid]['redacted_intervals'])\n",
    "        for uid, ts in zip(video_uids, start_end_times)\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212f71b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(data_df, x=\"x\", y=\"y\", color=\"feature_idx\",\n",
    "           hover_data=[\"feature_idx\", \"video_uid\", \"start_s\", \"end_s\", \"is_redacted\", \"has_redacted\", \"scenarios\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5842d4",
   "metadata": {},
   "source": [
    "# 4 - View The Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e7b15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here you can take two features by index and observe the region for which the features represent\n",
    "\n",
    "feature_idx_1 = 11678\n",
    "feature_idx_2 = 21936\n",
    "\n",
    "uid1 = video_uids[feature_idx_1]\n",
    "uid2 = video_uids[feature_idx_2]\n",
    "\n",
    "vid1_start_end = start_end_times[feature_idx_1]\n",
    "vid2_start_end = start_end_times[feature_idx_2]\n",
    "(uid1, vid1_start_end), (uid2, vid2_start_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c81440a",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_for_features[uid1]['scenarios'], meta_for_features[uid1]['redacted_intervals']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2df67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_for_features[uid2]['scenarios'], meta_for_features[uid2]['redacted_intervals']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b4d5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_clip(video_uid, start_end, clip_path, scale_size):\n",
    "    path_to_video = f\"{VIDEOS_DIR}/{video_uid}.mp4\"\n",
    "    t1 = start_end[0]\n",
    "    t2 = start_end[1]\n",
    "    dur = t2 - t1\n",
    "    ss_str=f\"{t1:.6f}\"\n",
    "    dur_str=f\"{dur:.6f}\"\n",
    "    \n",
    "    !ffmpeg -y -ss \"$ss_str\" -i \"$path_to_video\" -t \"$dur_str\" -vf \"scale=-1:$scale_size\" \"$clip_path\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af3f315",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_dir = \"/tmp/clips\"\n",
    "!rm -r $clip_dir\n",
    "!mkdir $clip_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4934e238",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_1_path = f\"{clip_dir}/clip1.mp4\"\n",
    "clip_2_path = f\"{clip_dir}/clip2.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce59d57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_clip(uid1, vid1_start_end, clip_1_path, 540)\n",
    "create_clip(uid2, vid2_start_end, clip_2_path, 540)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a53919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VideoFileClip(clip_1_path).ipython_display(maxduration=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f83cfd5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# VideoFileClip(clip_2_path).ipython_display(maxduration=1000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048db744",
   "metadata": {},
   "source": [
    "# Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa12840",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e87e17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save off some dim reduced features\n",
    "data = {}\n",
    "data[\"schema\"] = [\"start_sec\", \"end_sec\", \"embedding_vector\"]\n",
    "\n",
    "for idx, video_uid in enumerate(video_uids):\n",
    "    if video_uid not in data:\n",
    "        data[video_uid] = []\n",
    "    data[video_uid].append(\n",
    "        (\n",
    "            start_end_times[idx][0],\n",
    "            start_end_times[idx][1],\n",
    "            X_tsne[idx].tolist(),\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bb7478",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[video_uids[0]][0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc7ef0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(data, open(\"/tmp/data.json\", \"w\"), indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5857abb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
