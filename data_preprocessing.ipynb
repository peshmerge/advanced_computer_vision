{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pre-processing\n",
    "\n",
    "This code loads the videos, extracts frames and save as ap array files on disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries.\n",
    "import os\n",
    "import cv2\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import datetime as datetime\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "from moviepy.editor import *\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print num of GPUs if available to use\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set data directories and other parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data paths are defined here\n",
    "DATA_DIR = 'data'\n",
    "VIDEO_PATH = os.path.join(DATA_DIR, 'videos')\n",
    "ANNOTATION_PATH = os.path.join(DATA_DIR, 'annotations')\n",
    "TRAINING_PATH = os.path.join(VIDEO_PATH, 'training')\n",
    "TESTING_PATH = os.path.join(VIDEO_PATH, 'testing')\n",
    "VALIDATION_PATH = os.path.join(VIDEO_PATH, 'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the number of frames of a video that will be fed to the model as one sequence.\n",
    "SEQUENCE_LENGTH = 30\n",
    "\n",
    "# Set a minimum duration in seconds to extract sequence in multiples of\n",
    "MIN_DURATION = 150\n",
    "\n",
    "(DIMENSION_X, DIMENSION_Y, DIMENSION_C) = (224, 224, 3)\n",
    "\n",
    "# Get the names of all classes/categories in our dataset.\n",
    "CLASSES_LIST = os.listdir(TRAINING_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a easily readable class name mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_mapping = {\n",
    "'_cut___chop___slice_a_vegetable,_fruit,_or_meat_' : 'cut vegetables, herbs or meat',\n",
    "'browse_through_clothing_items_on_rack___shelf___hanger' : 'browse through clothing items',\n",
    "'clean___wipe_other_surface_or_object' : 'clean surface',\n",
    "'dig_or_till_the_soil_with_a_hoe_or_other_tool' : 'till soil with a hoe',\n",
    "'read_a_book___magazine___shopping_list_etc' : 'read a book',\n",
    "'throw_away_trash___put_trash_in_trash_can' : 'throw away trash',\n",
    "'wash_dishes___utensils___bakeware_etc' : 'wash utensils'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Show some stills from training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Matplotlib figure and specify the size of the figure.\n",
    "plt.figure(figsize = (20, 20))\n",
    "\n",
    "# Iterating through all the classes.\n",
    "for class_name in CLASSES_LIST:\n",
    "    if class_name.startswith('.'): continue\n",
    "    # Retrieve the list of all the video files present in the randomly selected Class Directory.\n",
    "    video_files_names_list = os.listdir(os.path.join(TRAINING_PATH, class_name))\n",
    "\n",
    "    # Randomly select a video file from the list retrieved from the randomly selected Class Directory.\n",
    "    selected_video_file_name = random.choice(video_files_names_list)\n",
    "    while not selected_video_file_name.endswith('.mp4'): selected_video_file_name = random.choice(video_files_names_list)\n",
    "\n",
    "    # Initialize a VideoCapture object to read from the video File.\n",
    "    video_reader = cv2.VideoCapture(os.path.join(TRAINING_PATH, class_name, selected_video_file_name))\n",
    "    \n",
    "    # Read the first frame of the video file.\n",
    "    _, bgr_frame = video_reader.read()\n",
    "\n",
    "    # Release the VideoCapture object. \n",
    "    video_reader.release()\n",
    "\n",
    "    # Convert the frame from BGR into RGB format. \n",
    "    rgb_frame = cv2.cvtColor(bgr_frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Display the frame.\n",
    "    plt.subplot(5, 4, CLASSES_LIST.index(class_name) + 1).set_title(class_mapping[class_name])\n",
    "    plt.imshow(rgb_frame)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read all videos, extract frams and save as nparrays \n",
    "\n",
    "This section should only be run once to create the nparrays for the dataset and save them to disk. The nparrays are then used in the next section to create the data generator. (**Run only once**)\n",
    "\n",
    "The file uploaded to drive can be downloaded and unzipped to the data directory instead of running this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from frames_extractor import video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_on_disk(data_path):\n",
    "    '''\n",
    "    This function will extract the data of the selected classes and create the required dataset.\n",
    "    Returns:\n",
    "        features:          A list containing the extracted frames of the videos.\n",
    "        labels:            A list containing the indexes of the classes associated with the videos.\n",
    "        video_files_paths: A list containing the paths of the videos in the disk.\n",
    "    '''\n",
    "    \n",
    "    # Iterating through all the classes mentioned in the classes list\n",
    "    for class_index, class_name in enumerate(CLASSES_LIST):\n",
    "        if class_name.startswith('.'): continue\n",
    "        \n",
    "        # Display the name of the class whose data is being extracted.\n",
    "        print(f'Extracting Data of Class: {class_name} from {data_path}')\n",
    "        \n",
    "        # Get the list of video files present in the specific class name directory.\n",
    "        files_list = os.listdir(os.path.join(data_path, class_name))\n",
    "        \n",
    "        # Iterate through all the files present in the files list.\n",
    "        for file_name in files_list:\n",
    "            if not file_name.endswith('.mp4'): continue\n",
    "            # Get the complete video path.\n",
    "            video_file_path = os.path.join(data_path, class_name, file_name)\n",
    "            vid = video(video_file_path)\n",
    "            # Extract the frames of the video file.\n",
    "            frames = vid.frames_extraction()\n",
    "\n",
    "            # Check if the extracted frames are equal to the SEQUENCE_LENGTH specified above.\n",
    "            # So ignore the vides having frames less than the SEQUENCE_LENGTH.\n",
    "            if len(frames) % SEQUENCE_LENGTH == 0:\n",
    "                # Append the data to their repective lists.\n",
    "                for i in range(0, len(frames), SEQUENCE_LENGTH):\n",
    "                    np.save(os.path.join(data_path, class_name, \n",
    "                        f'{file_name[:-4]}_{i}.npy'), \n",
    "                        np.asarray(frames[i:i+SEQUENCE_LENGTH]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Data of Class: browse_through_clothing_items_on_rack___shelf___hanger from data\\videos\\training\n",
      "Extracting Data of Class: clean___wipe_other_surface_or_object from data\\videos\\training\n",
      "Extracting Data of Class: dig_or_till_the_soil_with_a_hoe_or_other_tool from data\\videos\\training\n",
      "Extracting Data of Class: read_a_book___magazine___shopping_list_etc from data\\videos\\training\n",
      "Extracting Data of Class: throw_away_trash___put_trash_in_trash_can from data\\videos\\training\n",
      "Extracting Data of Class: wash_dishes___utensils___bakeware_etc from data\\videos\\training\n",
      "Extracting Data of Class: _cut___chop___slice_a_vegetable,_fruit,_or_meat_ from data\\videos\\training\n",
      "CPU times: total: 10min 36s\n",
      "Wall time: 2min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "create_dataset_on_disk(TRAINING_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Data of Class: browse_through_clothing_items_on_rack___shelf___hanger from data\\videos\\testing\n",
      "Extracting Data of Class: clean___wipe_other_surface_or_object from data\\videos\\testing\n",
      "Extracting Data of Class: dig_or_till_the_soil_with_a_hoe_or_other_tool from data\\videos\\testing\n",
      "Extracting Data of Class: read_a_book___magazine___shopping_list_etc from data\\videos\\testing\n",
      "Extracting Data of Class: throw_away_trash___put_trash_in_trash_can from data\\videos\\testing\n",
      "Extracting Data of Class: wash_dishes___utensils___bakeware_etc from data\\videos\\testing\n",
      "Extracting Data of Class: _cut___chop___slice_a_vegetable,_fruit,_or_meat_ from data\\videos\\testing\n",
      "CPU times: total: 2min 12s\n",
      "Wall time: 37.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "create_dataset_on_disk(TESTING_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Data of Class: browse_through_clothing_items_on_rack___shelf___hanger from data\\videos\\validation\n",
      "Extracting Data of Class: clean___wipe_other_surface_or_object from data\\videos\\validation\n",
      "Extracting Data of Class: dig_or_till_the_soil_with_a_hoe_or_other_tool from data\\videos\\validation\n",
      "Extracting Data of Class: read_a_book___magazine___shopping_list_etc from data\\videos\\validation\n",
      "Extracting Data of Class: throw_away_trash___put_trash_in_trash_can from data\\videos\\validation\n",
      "Extracting Data of Class: wash_dishes___utensils___bakeware_etc from data\\videos\\validation\n",
      "Extracting Data of Class: _cut___chop___slice_a_vegetable,_fruit,_or_meat_ from data\\videos\\validation\n",
      "CPU times: total: 2min 34s\n",
      "Wall time: 41.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "create_dataset_on_disk(VALIDATION_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code to zip npy files - no need to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 21.6 s\n",
      "Wall time: 37 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from zipfile import ZipFile\n",
    "zipObj = ZipFile('data_npy.zip', 'w')\n",
    "for partition_path in [TRAINING_PATH, TESTING_PATH, VALIDATION_PATH]:\n",
    "\tfor class_name in os.listdir(partition_path):\n",
    "\t\tfor video_file_name in os.listdir(os.path.join(partition_path, class_name)):\n",
    "\t\t\tif not video_file_name.endswith('.npy'): continue\n",
    "\t\t\tnparrayfile_path = os.path.join(partition_path, class_name, video_file_name)\n",
    "\t\t\tzipObj.write(nparrayfile_path)\n",
    "\n",
    "# close the Zip File\n",
    "zipObj.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample code to use the data generator to load videos instead of nparray files (Not required - will fail if run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from batch_data_generator import DataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_videos_and_labels_in_partition(partition_path):\n",
    "\tvideo_paths = []\n",
    "\tlabels = {}\n",
    "\tfor class_name in os.listdir(partition_path):\n",
    "\t\tif class_name not in CLASSES_LIST:\n",
    "\t\t\tprint(f'{class_name} not found in class list!')\n",
    "\t\t\tcontinue\n",
    "\t\tfor video_file_name in os.listdir(os.path.join(partition_path, class_name)):\n",
    "\t\t\tif not video_file_name.endswith('.mp4'): continue\n",
    "\t\t\tvideo_path = os.path.join(partition_path, class_name, video_file_name)\n",
    "\t\t\tvideo_paths.append(video_path)\n",
    "\t\t\tlabels[video_path] = CLASSES_LIST.index(class_name)\n",
    "\treturn video_paths, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the data generator and define parameters for training and validation data generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition = {}\n",
    "labels = {}\n",
    "partition['train'], labels['train'] = get_videos_and_labels_in_partition(TRAINING_PATH)\n",
    "partition['test'], labels['test'] = get_videos_and_labels_in_partition(TESTING_PATH)\n",
    "partition['validation'], labels['validation'] = get_videos_and_labels_in_partition(VALIDATION_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of training videos: ', len(partition['train']))\n",
    "print('Number of testing videos: ', len(partition['test']))\n",
    "print('Number of validation videos: ', len(partition['validation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_generator_params = {\n",
    "\t'load_video': True,\n",
    "\t'batch_size' : 80,\n",
    "\t'sequence_length' : SEQUENCE_LENGTH,\n",
    "\t'n_classes' : len(CLASSES_LIST),\n",
    "\t'min_duration' : MIN_DURATION,\n",
    "\t'shuffle' : True\n",
    "}\n",
    "\n",
    "validation_data_generator_params = {\n",
    "\t'load_video': True,\n",
    "\t'batch_size' : 20,\n",
    "\t'sequence_length' : SEQUENCE_LENGTH,\n",
    "\t'n_classes' : len(CLASSES_LIST),\n",
    "\t'min_duration' : MIN_DURATION,\n",
    "\t'shuffle' : True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_generator = DataGenerator(partition['train'], labels['train'], **train_data_generator_params)\n",
    "validation_generator = DataGenerator(partition['validation'], labels['validation'], **validation_data_generator_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To randomly use only a part of the dataset, use the following code instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_to_use = 0.5\n",
    "\n",
    "train_partition = np.random.choice(partition['train'], int(len(partition['train']) * part_to_use), replace = False)\n",
    "val_partition = np.random.choice(partition['validation'], int(len(partition['validation']) * part_to_use), replace = False)\n",
    "\n",
    "training_generator = DataGenerator(train_partition, labels['train'], **train_data_generator_params)\n",
    "validation_generator = DataGenerator(val_partition, labels['validation'], **validation_data_generator_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('ACVPR')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7b16c9da95f04883170e058a5ab5debfb744b1406582038da61280139aa5eca4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
