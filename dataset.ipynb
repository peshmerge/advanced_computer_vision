{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00e600b1-305c-4f35-8c49-ebb6869bc7d4",
   "metadata": {},
   "source": [
    "# Pre-Requisite Installations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b4499f-8dbc-44e8-a9d8-c6824047036e",
   "metadata": {},
   "source": [
    "Please do the following steps initially:\n",
    "- Install the AWS CLI from: https://aws.amazon.com/cli/\n",
    "- Open a command line and type `aws configure`\n",
    "- Leave the default region blank, and enter your AWS access id and secret key when prompted.\n",
    "\n",
    "**(NOTE: Requires python >= 3.8)**\n",
    "\n",
    "Dependencies (run the command in the next cell if you need these dependencies installed):\n",
    "- boto3\n",
    "- tqdm\n",
    "- moviepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4aed3b40-765c-4127-9578-0f26d9c4da94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run these commands to install dependencies\n",
    "# %pip install boto3\n",
    "# %pip install tqdm\n",
    "# %pip install moviepy\n",
    "# %pip install wget (not needed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e34712-40bb-4ef6-b101-ad358a668cb9",
   "metadata": {},
   "source": [
    "# Import everything that is needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c661bf5-2766-436b-aaef-505495a7e0e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# General imports\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import shutil\n",
    "import random\n",
    "import regex as re\n",
    "import warnings\n",
    "import uuid\n",
    "\n",
    "# Video clipping\n",
    "import datetime\n",
    "from moviepy.editor import *\n",
    "import subprocess\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Setup of ego4d downloads\n",
    "from zipfile import ZipFile\n",
    "from sys import platform\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "# Custom classes\n",
    "from utils import cd\n",
    "\n",
    "# Print num of GPUs if available to use\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3d13c3-6950-4008-899c-024325eb2200",
   "metadata": {},
   "source": [
    "# Download and Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e514531-f2fe-437e-ae2a-7cdd08481314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data paths that are defined\n",
    "data_dir = 'data'\n",
    "ego4d_setup_dir = 'ego4d_setup'\n",
    "video_path = os.path.join(data_dir, 'videos')\n",
    "annotation_path = os.path.join(data_dir, 'annotations')\n",
    "training_path = os.path.join(video_path, 'training')\n",
    "testing_path = os.path.join(video_path, 'testing')\n",
    "validation_path = os.path.join(video_path, 'validation')\n",
    "\n",
    "def perform_setup(delete_annotations=False, delete_clips=False, delete_setup=False, delete_data=False):\n",
    "    # If you want to delete already existing folders and contents\n",
    "    if delete_setup and os.path.exists(ego4d_setup_dir): shutil.rmtree(ego4d_setup_dir)\n",
    "    if delete_clips and os.path.exists(video_path): shutil.rmtree(video_path)\n",
    "    if delete_annotations and os.path.exists(annotation_path): shutil.rmtree(annotation_path)\n",
    "    if delete_data and os.path.exists(data_dir): shutil.rmtree(data_dir)\n",
    "\n",
    "    # If any dir doesn't exist, make it\n",
    "    if not os.path.exists(ego4d_setup_dir): os.makedirs(ego4d_setup_dir)\n",
    "    if not os.path.exists(annotation_path): os.makedirs(annotation_path)\n",
    "    if not os.path.exists(video_path): os.makedirs(video_path)\n",
    "    if not os.path.exists(training_path): os.makedirs(training_path)\n",
    "    if not os.path.exists(testing_path): os.makedirs(testing_path)\n",
    "    if not os.path.exists(validation_path): os.makedirs(validation_path)\n",
    "\n",
    "# Uncomment to setup the dataset\n",
    "# delete_annotations: resets data/annotations \n",
    "# delete_clips: resets data/videos\n",
    "# delete_setup: resets ego4d_setup directory (should be deleted normally anyway)\n",
    "# delete_data: deletes all of data directory and its subdirectories\n",
    "perform_setup(delete_setup=True, delete_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e13a01b",
   "metadata": {},
   "source": [
    "> Retrieve ego4d data retrieval tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5788c8cd-8157-4eb4-88bc-70a8dda25404",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading the setup zip file..\n",
      "Finished retrieving the setup files.\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the zip file for setup\n",
    "print('Downloading the setup zip file..')\n",
    "\n",
    "#Defining the zip file URL\n",
    "url = 'https://github.com/facebookresearch/Ego4d/archive/refs/heads/main.zip'\n",
    "# Split URL to get the file name\n",
    "filename = url.split('/')[-1]\n",
    "\n",
    "# Downloading the file by sending the request to the URL\n",
    "req = requests.get(url)\n",
    "\n",
    "# extracting the zip file contents\n",
    "zipfile= ZipFile(BytesIO(req.content))\n",
    "zipfile.extractall(ego4d_setup_dir)\n",
    "print('Finished retrieving the setup files.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7c64aaed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading annotations..\n",
      "Datasets to download: {'annotations'}\n",
      "Download Path: ego4d_data/v1\n",
      "Downloading Ego4D metadata json..\n",
      "Ego4D Metadata: ego4d_data/ego4d.json\n",
      "Checking requested datasets and versions...\n",
      "Created download directory for version 'v1' of dataset: 'annotations' at: ego4d_data/v1/annotations\n",
      "Retrieving object metadata from S3...\n",
      "Checking if latest file versions are already downloaded...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:00<00:00, 1343.93object/s]\n",
      " 10%|▉         | 3/31 [00:01<00:16,  1.66file/s]WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: ego4d-consortium-sharing.s3.us-west-1.amazonaws.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: ego4d-consortium-sharing.s3.us-west-1.amazonaws.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: ego4d-consortium-sharing.s3.us-west-1.amazonaws.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: ego4d-consortium-sharing.s3.us-west-1.amazonaws.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: ego4d-consortium-sharing.s3.us-west-1.amazonaws.com. Connection pool size: 10\n",
      "100%|██████████| 31/31 [00:01<00:00, 18.19file/s]\n",
      "  0%|          | 0.00/0.02M [00:00<?, ?b/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No existing videos to filter.\n",
      "Downloading 31 files..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 0.02M/0.02M [01:32<00:00, 233Mb/s]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking file integrity...\n",
      "Finished downloading and setting up annotations.\n"
     ]
    }
   ],
   "source": [
    "# Setting up the annotations and retrieving it\n",
    "def setup_annotations(annotation_regex):\n",
    "    # Check if annotations are already present\n",
    "    if os.path.exists(annotation_path):\n",
    "        files = next(os.walk(annotation_path), (None, None, []))[2]\n",
    "        rgx = re.compile(annotation_regex)\n",
    "        newlist = list(filter(rgx.match, files))\n",
    "\n",
    "        # If not present, then download the annotations and save them\n",
    "        if not newlist:\n",
    "            print('Downloading annotations..')\n",
    "\n",
    "            # Command to download ALL annotations\n",
    "            command = ['python', '-m', 'ego4d.cli.cli', '--output_directory=ego4d_data', '--datasets', 'annotations', '--yes']\n",
    "            with cd(os.path.join(ego4d_setup_dir, \"Ego4d-main\")):\n",
    "                subprocess.run(command, check=True)\n",
    "            # Copy and save only needed annotations in the data directory\n",
    "            annotation_dir = os.path.join(ego4d_setup_dir, \"Ego4d-main\", \"ego4d_data\", \"v1\", \"annotations\")\n",
    "            for file in os.listdir(annotation_dir):\n",
    "                if \"moments\" in file: # TODO: Should be changed later to not have string\n",
    "                    shutil.copy(os.path.join(annotation_dir, file), os.path.join(annotation_path))\n",
    "            print('Finished downloading and setting up annotations.')\n",
    "        else:\n",
    "            print('Annotations already present!')\n",
    "        \n",
    "# Setting up the annotations\n",
    "# annnotation_regex: regular expression of the files you want to copy from ALL annotations\n",
    "setup_annotations(\"moments*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee899e5-8327-4cd1-b6a7-7d068d41ebf4",
   "metadata": {},
   "source": [
    "# Pre-Process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc4fc5a",
   "metadata": {},
   "source": [
    "### Process moments_train.json\n",
    "> Process moments_train.json and filter videos with given classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e7c43cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# The classes to be used in this project\n",
    "classes = [\"wash_dishes_/_utensils_/_bakeware_etc.\", \"use_phone\", \"browse_through_clothing_items_on_rack_/_shelf_/_hanger\"]\n",
    "# Training, testing, and validation annotation files\n",
    "# Filtered clip uids dictionary containing only classes listed above\n",
    "filtered_dict = {\n",
    "    'training': {\n",
    "        'file_name': 'moments_train.json',\n",
    "        'count': 15,\n",
    "        'data': {}\n",
    "    },\n",
    "    'testing': {\n",
    "        'file_name': 'moments_val.json',\n",
    "        'count': 5,\n",
    "        'data': {}\n",
    "    },\n",
    "    'validation': {\n",
    "        'file_name': 'moments_val.json',\n",
    "        'count': 5,\n",
    "        'data': {}\n",
    "    }\n",
    "}\n",
    "\n",
    "for data_type in filtered_dict:\n",
    "    with open(os.path.join(annotation_path, filtered_dict[data_type]['file_name']), 'r') as json_file:\n",
    "        # Load the annotation file\n",
    "        loaded_json = json.load(json_file)\n",
    "\n",
    "        # For each video and for each clips within the video\n",
    "        # retrieve clip_uid, video_uids, label, start_time, and end_time\n",
    "        for video in loaded_json['videos']:\n",
    "            for clip in video['clips']:\n",
    "                filtered_dict[data_type]['data'][clip[\"clip_uid\"]] = {\n",
    "                    \"video_uid\": video[\"video_uid\"],\n",
    "                    \"annotations\": {}\n",
    "                }\n",
    "                annotation = clip[\"annotations\"][0]\n",
    "                for label_item in annotation[\"labels\"]:\n",
    "                    label = label_item[\"label\"]\n",
    "                    if label in classes and (label_item[\"end_time\"] - label_item[\"start_time\"] >= 5):\n",
    "                        if label in filtered_dict[data_type]['data'][clip[\"clip_uid\"]][\"annotations\"]:\n",
    "                            filtered_dict[data_type]['data'][clip[\"clip_uid\"]][\"annotations\"][label].append({\n",
    "                                \"start_time\": label_item[\"start_time\"],\n",
    "                                \"end_time\": label_item[\"end_time\"]\n",
    "                            })\n",
    "                        else:\n",
    "                            filtered_dict[data_type]['data'][clip[\"clip_uid\"]][\"annotations\"][label] = [{\n",
    "                                \"start_time\": label_item[\"start_time\"],\n",
    "                                \"end_time\": label_item[\"end_time\"]\n",
    "                            }]\n",
    "                # Filter to make sure no clips with empty annotations are taken\n",
    "                if not filtered_dict[data_type]['data'][clip[\"clip_uid\"]][\"annotations\"]:\n",
    "                    del filtered_dict[data_type]['data'][clip[\"clip_uid\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "03b3e2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(filtered_dict))\n",
    "# with open('test.json', 'w') as jp:\n",
    "#     json.dump(filtered_dict, jp, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446d6f92",
   "metadata": {},
   "source": [
    "### Trim videos into clips\n",
    "> Using moviepy, split videos into clips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "134d7734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to cut/trim the video to desired lengths and save it\n",
    "def cut_video(video_path, times, save_path):\n",
    "    # Load the video once and close using context manager\n",
    "    with VideoFileClip(video_path) as vid_clip:\n",
    "        for segment in times:\n",
    "            # Segment information and random filename generation\n",
    "            start_time = segment['start_time']\n",
    "            end_time = segment['end_time']\n",
    "            fileName = f\"{uuid.uuid1()}.mp4\"\n",
    "\n",
    "            # Convert the amount of seconds in time xx:xx:xx.xxxxxx\n",
    "            start_time = str(datetime.timedelta(seconds = start_time))\n",
    "            end_time = str(datetime.timedelta(seconds = end_time))\n",
    "\n",
    "            # Clip the video and save it to the specified path\n",
    "            clip = vid_clip.subclip(start_time, end_time)\n",
    "            if not os.path.exists(save_path): os.makedirs(save_path)\n",
    "            clip.write_videofile(os.path.join(save_path, fileName))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c95fc5c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets to download: {'clips'}\n",
      "Download Path: temp_clip/v1\n",
      "Downloading Ego4D metadata json..\n",
      "Ego4D Metadata: temp_clip/ego4d.json\n",
      "Checking requested datasets and versions...\n",
      "Created download directory for version 'v1' of dataset: 'clips' at: temp_clip/v1/clips\n",
      "Only downloading a subset of the video files because the 'video_uids' flag has been set on the command line or in the config file. A total of 1 video files will be downloaded.\n",
      "\n",
      "Retrieving object metadata from S3...\n",
      "Checking if latest file versions are already downloaded...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1175.20object/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.94file/s]\n",
      "  0%|          | 0.00/666k [00:00<?, ?b/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No existing videos to filter.\n",
      "Downloading 1 files..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 666k/666k [00:08<00:00, 80.7Mb/s] \n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'5123a4e0-afd2-4e6b-8414-161fbdb71d6f'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [34], line 76\u001b[0m\n\u001b[1;32m     71\u001b[0m     shutil\u001b[38;5;241m.\u001b[39mrmtree(ego4d_setup_dir)\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# Download and setup clips\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# filtered_dict: previously filtered dictionary of clips\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# video_path: path to save the clips\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m setup_clips(filtered_dict, video_path)\n",
      "Cell \u001b[0;32mIn [34], line 62\u001b[0m, in \u001b[0;36msetup_clips\u001b[0;34m(filtered_annotations, save_path, overwrite)\u001b[0m\n\u001b[1;32m     59\u001b[0m     subprocess\u001b[38;5;241m.\u001b[39mrun(command, check\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# Get the clip information and trim the video\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m clip_info \u001b[38;5;241m=\u001b[39m \u001b[43mfiltered_annotations\u001b[49m\u001b[43m[\u001b[49m\u001b[43mclip_uid\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m clip_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mannotations\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m     64\u001b[0m     folder_label \u001b[38;5;241m=\u001b[39m label\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: '5123a4e0-afd2-4e6b-8414-161fbdb71d6f'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking file integrity...\n"
     ]
    }
   ],
   "source": [
    "%%capture cap --no-stderr\n",
    "# ^ To save the output to external file because it's waaaaay too large to display in notebook\n",
    "# Function to retrieve a sample of clips for each class\n",
    "def generate_clip_uids(filtered_annotations):\n",
    "    # Seperate clip uids by their class\n",
    "    all_clips_dict = {\n",
    "        'training': {},\n",
    "        'testing': {},\n",
    "        'validation': {}\n",
    "    }\n",
    "    for clip_type in all_clips_dict:\n",
    "        for clip_uid, clip_info in filtered_annotations[clip_type]['data'].items():\n",
    "            for annotation in clip_info[\"annotations\"]:\n",
    "                if annotation in all_clips_dict[clip_type]:\n",
    "                    all_clips_dict[clip_type][annotation].append(clip_uid)\n",
    "                else:\n",
    "                    all_clips_dict[clip_type][annotation] = [clip_uid]\n",
    "        # Grab random sample of num_clips for each class\n",
    "        for annotation in all_clips_dict[clip_type]:\n",
    "            all_clips_dict[clip_type][annotation] = random.sample(all_clips_dict[clip_type][annotation], filtered_annotations[clip_type]['count'])\n",
    "    return all_clips_dict\n",
    "\n",
    "\n",
    "# Function to download and setup the clips \n",
    "def setup_clips(filtered_annotations, save_path, overwrite=False):\n",
    "    # Check if the clips already exist if we are not overwriting\n",
    "    if not overwrite:\n",
    "        dirs = next(os.walk(video_path), (None, None, []))[1]\n",
    "        for dir in dirs:\n",
    "            subdirs = next(os.walk(video_path, dir), (None, None, []))[2]\n",
    "            for subdir in subdirs:\n",
    "                files = next(os.walk(os.path.join(video_path, dir, subdir)), (None, None, []))[2]\n",
    "                if dir.replace(\";\", \"/\") in all_clips_dict['training'] and files:\n",
    "                    warnings.warn(\"Clips may already exist. If you want to redo the process, set the `overwrite` argument to true while calling the function.\")\n",
    "                    return\n",
    "\n",
    "    # Get all the randomly generated clip samples and go through them\n",
    "    all_clips_dict = generate_clip_uids(filtered_annotations)\n",
    "\n",
    "    # Go through each type of data (training, testing, validation)\n",
    "    for data_type in filtered_annotations:\n",
    "        for cls, clip_uids in all_clips_dict[data_type].items():\n",
    "            useable_name = cls.replace(\"/\", \";\") # Paths can't have / in their name so, replace it\n",
    "\n",
    "            # Make sure the required path exists without old items\n",
    "            if os.path.exists(os.path.join(video_path, data_type, useable_name)): shutil.rmtree(os.path.join(video_path, data_type, useable_name))\n",
    "            os.makedirs(os.path.join(video_path, data_type, useable_name))\n",
    "\n",
    "            print(f\"Processing clips for class: {cls}\")\n",
    "            for clip_uid in clip_uids:\n",
    "                # Command to retrieve clip by its uid\n",
    "                command = ['python', '-m', 'ego4d.cli.cli', '--output_directory=temp_clip', \n",
    "                '--datasets', 'clips', '--video_uids', clip_uid, '--yes']\n",
    "                # Path to the downloaded clip\n",
    "                full_vid_path = os.path.join(ego4d_setup_dir, \"Ego4d-main\", \"temp_clip\", \"v1\", \"clips\")\n",
    "                \n",
    "                # Use context manager to ensure any change in directory is returned to original\n",
    "                with cd(os.path.join(ego4d_setup_dir, \"Ego4d-main\")):\n",
    "                    # Download the video\n",
    "                    subprocess.run(command, check=True)\n",
    "                    \n",
    "                # Get the clip information and trim the video\n",
    "                clip_info = filtered_annotations[data_type]['data'][clip_uid]\n",
    "                for label in clip_info['annotations']:\n",
    "                    folder_label = label.replace(\"/\", \";\")\n",
    "                    cut_video(os.path.join(full_vid_path, f\"{clip_uid}.mp4\"), clip_info['annotations'][label], os.path.join(video_path, data_type, folder_label))\n",
    "                \n",
    "                # Clean up after for the specific clip\n",
    "                shutil.rmtree(os.path.join(ego4d_setup_dir, \"Ego4d-main\", \"temp_clip\"))\n",
    "    \n",
    "    # Clean up the overall setup directory\n",
    "    shutil.rmtree(ego4d_setup_dir)\n",
    "\n",
    "# Download and setup clips\n",
    "# filtered_dict: previously filtered dictionary of clips\n",
    "# video_path: path to save the clips\n",
    "setup_clips(filtered_dict, video_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d4e681-348f-49d1-b098-c695cee5b743",
   "metadata": {},
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569bc079-a314-437d-bd0c-c4eac9fc5c77",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87464f4-5c76-4e10-a266-f04fa25098d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axs = plt.subplots(nrows=3, ncols=1, figsize=(15, 15))\n",
    "\n",
    "# # flatten the axis into a 1-d array to make it easier to access each axes\n",
    "# axs = axs.flatten()\n",
    "\n",
    "# # iterate through and enumerate the files, use i to index the axes\n",
    "# for i in range(3):\n",
    "#     sample = train_dataset[i]\n",
    "\n",
    "#     # add the image to the axes\n",
    "#     axs[i].imshow(sample['image'])\n",
    "#     axs[i].axis('off')\n",
    "\n",
    "# # add a figure title\n",
    "# fig.suptitle('Visualizing Training Dataset', fontsize=18)\n",
    "\n",
    "# fig, axs = plt.subplots(nrows=3, ncols=1, figsize=(15, 15))\n",
    "\n",
    "# # flatten the axis into a 1-d array to make it easier to access each axes\n",
    "# axs = axs.flatten()\n",
    "\n",
    "# # iterate through and enumerate the files, use i to index the axes\n",
    "# for i in range(3):\n",
    "#     sample = test_dataset[i]\n",
    "\n",
    "#     # add the image to the axes\n",
    "#     axs[i].imshow(sample['image'])\n",
    "#     axs[i].axis('off')\n",
    "\n",
    "# # add a figure title\n",
    "# fig.suptitle('Visualizing Testing Dataset', fontsize=18)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('acvpr')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "3abfcb6a5852706a2368fe780626157966aa0a94fc44e414e400fd6502757207"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
